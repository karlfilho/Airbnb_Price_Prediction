{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 643 entries, 0 to 642\n",
      "Data columns (total 42 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   roomType                        643 non-null    object \n",
      " 1   roomPrice                       643 non-null    float64\n",
      " 2   qualityBadge                    643 non-null    object \n",
      " 3   rating                          643 non-null    float64\n",
      " 4   countReviews                    643 non-null    float64\n",
      " 5   Air Conditioning                643 non-null    int64  \n",
      " 6   TV                              643 non-null    int64  \n",
      " 7   Hair Dryer                      643 non-null    int64  \n",
      " 8   Bathroom                        643 non-null    int64  \n",
      " 9   Ethernet connection             643 non-null    int64  \n",
      " 10  Kitchen                         643 non-null    int64  \n",
      " 11  Elevator                        643 non-null    int64  \n",
      " 12  Luggage Dropoff Allowed         643 non-null    int64  \n",
      " 13  Smoke Alarm                     643 non-null    int64  \n",
      " 14  WiFi                            643 non-null    int64  \n",
      " 15  Parking                         643 non-null    int64  \n",
      " 16  Pets Allowed                    643 non-null    int64  \n",
      " 17  EV Charger                      643 non-null    int64  \n",
      " 18  Bedroom                         643 non-null    int64  \n",
      " 19  Fire pit                        643 non-null    int64  \n",
      " 20  Lit path to the guest entrance  643 non-null    int64  \n",
      " 21  Waterfront                      643 non-null    int64  \n",
      " 22  Long term stays allowed         643 non-null    int64  \n",
      " 23  Bathtub                         643 non-null    int64  \n",
      " 24  Laundry room                    643 non-null    int64  \n",
      " 25  Security Cameras                643 non-null    int64  \n",
      " 26  Baby bath                       643 non-null    int64  \n",
      " 27  Pool                            643 non-null    int64  \n",
      " 28  Microwave                       643 non-null    int64  \n",
      " 29  HDTV                            643 non-null    int64  \n",
      " 30  View                            643 non-null    int64  \n",
      " 31  Carbon Monoxide Alarm           643 non-null    int64  \n",
      " 32  Refrigerator                    643 non-null    int64  \n",
      " 33  Smoking allowed                 643 non-null    int64  \n",
      " 34  Patio                           643 non-null    int64  \n",
      " 35  High Chair                      643 non-null    int64  \n",
      " 36  Sauna                           643 non-null    int64  \n",
      " 37  Crib                            643 non-null    int64  \n",
      " 38  Washer                          643 non-null    int64  \n",
      " 39  Accessible                      643 non-null    int64  \n",
      " 40  Breakfast                       643 non-null    int64  \n",
      " 41  is_new                          643 non-null    int64  \n",
      "dtypes: float64(3), int64(37), object(2)\n",
      "memory usage: 211.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Carregando o conjunto de dados no IDE\n",
    "data = pd.read_csv('datasets/cleaned_final_dataset.csv')\n",
    "data = data.drop(columns='roomURL')\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalização: As variáveis numéricas (roomPrice, rating, countReviews) foram normalizadas.\n",
    "- Codificação: As variáveis categóricas (roomType, qualityBadge) foram codificadas usando one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((643, 56),\n",
       " ['rating',\n",
       "  'countReviews',\n",
       "  'Air Conditioning',\n",
       "  'TV',\n",
       "  'Hair Dryer',\n",
       "  'Bathroom',\n",
       "  'Ethernet connection',\n",
       "  'Kitchen',\n",
       "  'Elevator',\n",
       "  'Luggage Dropoff Allowed',\n",
       "  'Smoke Alarm',\n",
       "  'WiFi',\n",
       "  'Parking',\n",
       "  'Pets Allowed',\n",
       "  'EV Charger',\n",
       "  'Bedroom',\n",
       "  'Fire pit',\n",
       "  'Lit path to the guest entrance',\n",
       "  'Waterfront',\n",
       "  'Long term stays allowed',\n",
       "  'Bathtub',\n",
       "  'Laundry room',\n",
       "  'Security Cameras',\n",
       "  'Baby bath',\n",
       "  'Pool',\n",
       "  'Microwave',\n",
       "  'HDTV',\n",
       "  'View',\n",
       "  'Carbon Monoxide Alarm',\n",
       "  'Refrigerator',\n",
       "  'Smoking allowed',\n",
       "  'Patio',\n",
       "  'High Chair',\n",
       "  'Sauna',\n",
       "  'Crib',\n",
       "  'Washer',\n",
       "  'Accessible',\n",
       "  'Breakfast',\n",
       "  'is_new',\n",
       "  'roomType_Apartamento',\n",
       "  'roomType_Cabana',\n",
       "  'roomType_Casa',\n",
       "  'roomType_Chalé',\n",
       "  'roomType_Condomínio',\n",
       "  'roomType_Contêiner',\n",
       "  'roomType_Hotel',\n",
       "  'roomType_Loft',\n",
       "  'roomType_Lugar',\n",
       "  'roomType_Microcasa',\n",
       "  'roomType_Pousada',\n",
       "  'roomType_Quarto',\n",
       "  'roomType_Suíte',\n",
       "  'roomType_Trailer',\n",
       "  'qualityBadge_no_class',\n",
       "  'qualityBadge_preferido',\n",
       "  'qualityBadge_superhost'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_cols.remove('roomPrice')  # Exclude the target variable from normalization\n",
    "\n",
    "# Create a column transformer with normalization for numerical columns and one-hot encoding for categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply transformations\n",
    "data_preprocessed = preprocessor.fit_transform(data)\n",
    "\n",
    "# Show the shape of the transformed data and the feature names after one-hot encoding\n",
    "transformed_feature_names = (numerical_cols + \n",
    "                             list(preprocessor.named_transformers_['cat'].get_feature_names_out()))\n",
    "\n",
    "data_preprocessed.shape, transformed_feature_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar dividindo os dados e construindo os primeiros modelos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((514, 56), (129, 56))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract the target variable 'roomPrice'\n",
    "y = data['roomPrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'MSE': 13566.658914728681,\n",
       "  'MAE': 54.89922480620155,\n",
       "  'R2': 0.7367876765185619},\n",
       " 'GBM': {'MSE': 12905.541131140531,\n",
       "  'MAE': 84.05545326467916,\n",
       "  'R2': 0.7496142942589266},\n",
       " 'SVM': {'MSE': 53178.5705277941,\n",
       "  'MAE': 177.2879256077671,\n",
       "  'R2': -0.03173929528412134},\n",
       " 'Random Forest': {'MSE': 9361.369593544561,\n",
       "  'MAE': 62.748945968528055,\n",
       "  'R2': 0.8183762223866134}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the models\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "svm = SVR()\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train and predict with Decision Tree\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Train and predict with GBM\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "\n",
    "# Train and predict with SVM\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Train and predict with Random Forest\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate metrics for Decision Tree\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "# Calculate metrics for GBM\n",
    "mse_gbm = mean_squared_error(y_test, y_pred_gbm)\n",
    "mae_gbm = mean_absolute_error(y_test, y_pred_gbm)\n",
    "r2_gbm = r2_score(y_test, y_pred_gbm)\n",
    "\n",
    "# Calculate metrics for SVM\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
    "mae_svm = mean_absolute_error(y_test, y_pred_svm)\n",
    "r2_svm = r2_score(y_test, y_pred_svm)\n",
    "\n",
    "# Calculate metrics for Random Forest\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Results\n",
    "{\n",
    "    \"Decision Tree\": {\"MSE\": mse_tree, \"MAE\": mae_tree, \"R2\": r2_tree},\n",
    "    \"GBM\": {\"MSE\": mse_gbm, \"MAE\": mae_gbm, \"R2\": r2_gbm},\n",
    "    \"SVM\": {\"MSE\": mse_svm, \"MAE\": mae_svm, \"R2\": r2_svm},\n",
    "    \"Random Forest\": {\"MSE\": mse_rf, \"MAE\": mae_rf, \"R2\": r2_rf}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise:\n",
    "Árvores de Decisão e GBM mostraram desempenhos relativamente bons com R² em torno de 0.74 e 0.75, respectivamente, indicando que esses modelos explicam bem a variância nos dados.\n",
    "GBM teve uma ligeira vantagem em termos de MSE, mas apresentou um MAE mais alto comparado ao modelo de Árvore de Decisão.\n",
    "SVM teve um desempenho significativamente pior, com um R² negativo, sugerindo que este modelo não é adequado para este conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Hiperparâmetros do Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': None,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 200},\n",
       " 0.6861318026322005)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize the Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Fit the Grid Search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados do Ajuste de Hiperparâmetros\n",
    "Após a execução da busca em grade, os melhores parâmetros para o modelo Random Forest foram encontrados, apesar de alguns erros devido ao uso do valor 'auto' no parâmetro max_features. Aqui estão os resultados das métricas de avaliação do modelo ajustado:\n",
    "\n",
    "**Random Forest Ajustado:**   \n",
    "RMSE (Root Mean Squared Error): 0.454   \n",
    "MAE (Mean Absolute Error): 0.302    \n",
    "R² (R-squared): 0.814    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest (best hyperparameters)': {'MSE': 9739.656711515541,\n",
       "  'MAE': 66.72808202150271,\n",
       "  'R2': 0.8110369185911785}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the best hyperparameters found for training the final Random Forest model\n",
    "best_params = {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "\n",
    "# Initialize the Random Forest model with the best hyperparameters\n",
    "rf_best = RandomForestRegressor(**best_params, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf_best = rf_best.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the best Random Forest model\n",
    "mse_rf_best = mean_squared_error(y_test, y_pred_rf_best)\n",
    "mae_rf_best = mean_absolute_error(y_test, y_pred_rf_best)\n",
    "r2_rf_best = r2_score(y_test, y_pred_rf_best)\n",
    "\n",
    "# Results for the best Random Forest model\n",
    "{\n",
    "    \"Random Forest (best hyperparameters)\": {\"MSE\": mse_rf_best, \"MAE\": mae_rf_best, \"R2\": r2_rf_best}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação Predição Conforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.icp import IcpRegressor\n",
    "from nonconformist.nc import NcFactory, AbsErrorErrFunc\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base regressor\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=42)\n",
    "\n",
    "# Define the nonconformity function\n",
    "nc = NcFactory.create_nc(rf, err_func=AbsErrorErrFunc())\n",
    "\n",
    "# Initialize the inductive conformal predictor\n",
    "icp = IcpRegressor(nc)\n",
    "\n",
    "# Fit the model\n",
    "icp.fit(X_train, y_train)\n",
    "\n",
    "# Calibrate the model using part of the training data\n",
    "icp.calibrate(X_train, y_train)\n",
    "\n",
    "# Make predictions with confidence intervals on the test data\n",
    "prediction_intervals = icp.predict(X_test, significance=0.1)  # 90% confidence intervals\n",
    "\n",
    "# Extract lower and upper bounds\n",
    "lower_bounds = prediction_intervals[:, 0]\n",
    "upper_bounds = prediction_intervals[:, 1]\n",
    "point_predictions = (lower_bounds + upper_bounds) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Conformal Prediction': {'MSE': 9739.656711515541, 'MAE': 66.72808202150271, 'R2': 0.8110369185911785, 'Interval Width': 195.83516666666662, 'Coverage': 0.7596899224806202}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse_conformal = mean_squared_error(y_test, point_predictions)\n",
    "mae_conformal = mean_absolute_error(y_test, point_predictions)\n",
    "r2_conformal = r2_score(y_test, point_predictions)\n",
    "\n",
    "interval_width = np.mean(upper_bounds - lower_bounds)\n",
    "coverage = np.mean((y_test >= lower_bounds) & (y_test <= upper_bounds))\n",
    "\n",
    "results = {\n",
    "    \"Conformal Prediction\": {\n",
    "        \"MSE\": mse_conformal,\n",
    "        \"MAE\": mae_conformal,\n",
    "        \"R2\": r2_conformal,\n",
    "        \"Interval Width\": interval_width,\n",
    "        \"Coverage\": coverage\n",
    "    }\n",
    "}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.05: {'MSE': 9739.656711515541, 'MAE': 66.72808202150271, 'R2': 0.8110369185911785, 'Interval Width': 288.87520238095226, 'Coverage': 0.8604651162790697}, 0.1: {'MSE': 9739.656711515541, 'MAE': 66.72808202150271, 'R2': 0.8110369185911785, 'Interval Width': 195.83516666666662, 'Coverage': 0.7596899224806202}, 0.15: {'MSE': 9739.656711515541, 'MAE': 66.72808202150271, 'R2': 0.8110369185911785, 'Interval Width': 133.89202444137683, 'Coverage': 0.6434108527131783}}\n"
     ]
    }
   ],
   "source": [
    "# Define diferentes níveis de significância para ajustar a cobertura\n",
    "significance_levels = [0.05, 0.10, 0.15]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for significance in significance_levels:\n",
    "    # Make predictions with the specified significance level\n",
    "    prediction_intervals = icp.predict(X_test, significance=significance)\n",
    "    \n",
    "    # Extract lower and upper bounds\n",
    "    lower_bounds = prediction_intervals[:, 0]\n",
    "    upper_bounds = prediction_intervals[:, 1]\n",
    "    point_predictions = (lower_bounds + upper_bounds) / 2\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_conformal = mean_squared_error(y_test, point_predictions)\n",
    "    mae_conformal = mean_absolute_error(y_test, point_predictions)\n",
    "    r2_conformal = r2_score(y_test, point_predictions)\n",
    "    interval_width = np.mean(upper_bounds - lower_bounds)\n",
    "    coverage = np.mean((y_test >= lower_bounds) & (y_test <= upper_bounds))\n",
    "    \n",
    "    results[significance] = {\n",
    "        \"MSE\": mse_conformal,\n",
    "        \"MAE\": mae_conformal,\n",
    "        \"R2\": r2_conformal,\n",
    "        \"Interval Width\": interval_width,\n",
    "        \"Coverage\": coverage\n",
    "    }\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados com 90% Confiança:\n",
    "Erro Quadrático Médio (MSE): 9739.66\n",
    "Erro Absoluto Médio (MAE): 66.73\n",
    "Coeficiente de Determinação (R²): 0.81\n",
    "Largura do Intervalo Médio: 195.84\n",
    "Cobertura: 75.97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Conformal Prediction (90% confidence)': {'MSE': 9739.656711515541, 'MAE': 66.72808202150271, 'R2': 0.8110369185911785, 'Interval Width': 195.83516666666662, 'Coverage': 0.7596899224806202}}\n"
     ]
    }
   ],
   "source": [
    "from nonconformist.icp import IcpRegressor\n",
    "from nonconformist.nc import NcFactory, AbsErrorErrFunc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize the base regressor\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=42)\n",
    "\n",
    "# Define the nonconformity function\n",
    "nc = NcFactory.create_nc(rf, err_func=AbsErrorErrFunc())\n",
    "\n",
    "# Initialize the inductive conformal predictor\n",
    "icp = IcpRegressor(nc)\n",
    "\n",
    "# Fit the model\n",
    "icp.fit(X_train, y_train)\n",
    "\n",
    "# Calibrate the model using part of the training data\n",
    "icp.calibrate(X_train, y_train)\n",
    "\n",
    "# Make predictions with confidence intervals on the test data\n",
    "significance = 0.10  # 90% confidence intervals\n",
    "prediction_intervals = icp.predict(X_test, significance=significance)\n",
    "\n",
    "# Extract lower and upper bounds\n",
    "lower_bounds = prediction_intervals[:, 0]\n",
    "upper_bounds = prediction_intervals[:, 1]\n",
    "point_predictions = (lower_bounds + upper_bounds) / 2\n",
    "\n",
    "# Calculate metrics\n",
    "mse_conformal = mean_squared_error(y_test, point_predictions)\n",
    "mae_conformal = mean_absolute_error(y_test, point_predictions)\n",
    "r2_conformal = r2_score(y_test, point_predictions)\n",
    "interval_width = np.mean(upper_bounds - lower_bounds)\n",
    "coverage = np.mean((y_test >= lower_bounds) & (y_test <= upper_bounds))\n",
    "\n",
    "results = {\n",
    "    \"Conformal Prediction (90% confidence)\": {\n",
    "        \"MSE\": mse_conformal,\n",
    "        \"MAE\": mae_conformal,\n",
    "        \"R2\": r2_conformal,\n",
    "        \"Interval Width\": interval_width,\n",
    "        \"Coverage\": coverage\n",
    "    }\n",
    "}\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
